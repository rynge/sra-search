#!/bin/bash

set -e

if [ ! -n "$1" -o ! -n "$2" ]; then
        echo "Usage: ./`basename $0` <file with list of SRA IDs> <reference basename>"
        echo "Example: ./`basename $0` tests/01/sra_ids.txt tests/01/crassphage.fna"
        exit $E_BADARGS
fi

SRA_IDS=`basename $1`
REF_FILENAME=`basename $2`

export REF_BASENAME=`echo $REF_FILENAME | perl -p -e 's/\.[a-zA-Z]+$//'`
if [ "$REF_BASENAME" = "$REF_FILENAME" ]; then
    # ref file came in without extension - make a copy
    cp $REF_FILENAME $REF_FILENAME.fna
    REF_FILENAME="$REF_FILENAME.fna"
fi

echo "Creating a DAG for running $SRA_IDS against $REF_BASENAME ..."

TOP_DIR=`dirname $0`
TOP_DIR=`cd $TOP_DIR && pwd`

# used for directories, and track usage
export RUN_ID=`uuidgen`

# if not already defined, create a work dir for this run
if [ "x$WORK_DIR" = "x" ]; then
    WORK_DIR=$HOME/runs/$RUN_ID
    mkdir -p $WORK_DIR
    echo
    echo "Work directory is $WORK_DIR"

    # make copies of the input files
    cp $1 $WORK_DIR/
    cp $2 $WORK_DIR/$REF_BASENAME.fna
fi

# and of the templates/job files
cd $TOP_DIR
cp *.sh *.template $WORK_DIR/

cd $WORK_DIR

# index the ref genome
envsubst <index.template >index.submit
cat >>sra.dag <<EOF
JOB  INDEX  index.submit
EOF

# define final job before search jobs, so we can reference it in the
# parent-child relationships for the actual jobs
envsubst <local-prepare-outputs.template >local-prepare-outputs.submit
cat >>sra.dag <<EOF
JOB  PREPARE_OUTPUTS  local-prepare-outputs.submit
EOF

# build the HTCondor submit files and DAG
SRA_COUNT=0
JOB_COUNT=0
SUB_DIR=0
SRA_ID_LIST=""
OUTPUT_FILES=""
for SRA_ID in `cat $SRA_IDS | sort | uniq`; do
   
    # TODO: handle missing inputs smarter way
    if [ ! -e /nas/wrangler/NCBI/SRA/Downloads/fastq/$SRA_ID.fastq.gz ]; then
        echo "Warning: Missing SRA data: $SRA_ID"
        continue
    fi

    SRA_COUNT=$(($SRA_COUNT + 1))

    # for the job template
    export SRA_ID_LIST="$SRA_ID_LIST $SRA_ID"
    export OUTPUT_FILES=`echo "$OUTPUT_FILES, $SRA_ID.bam, $SRA_ID.bam.bai" | sed 's/^ *,//'`
    
    # 5 searches per job
    if [ $(($SRA_COUNT % 5)) -eq 0 ]; then
    
        # 100 jobs per directory
        if [ $(($JOB_COUNT % 100)) -eq 0 ]; then
            export SUB_DIR=$(($SUB_DIR + 1))
            mkdir -p $SUB_DIR
        fi
        export JOB_COUNT=$(($JOB_COUNT + 1))

        # generate the job from the template    
        envsubst <search.template >$SUB_DIR/$JOB_COUNT.submit

        # add job to the dag
        cat >>sra.dag <<EOF

JOB  ID$JOB_COUNT  $JOB_COUNT.submit  DIR $SUB_DIR
RETRY ID$JOB_COUNT 3
PARENT INDEX CHILD ID$JOB_COUNT
PARENT ID$JOB_COUNT CHILD PREPARE_OUTPUTS
EOF
    	SRA_ID_LIST=""
    	OUTPUT_FILES=""
    fi

done

# leftover jobs
if [ "X$SRA_ID_LIST" != "X" ]; then
    # 100 jobs per directory
    if [ $(($JOB_COUNT % 100)) -eq 0 ]; then
        export SUB_DIR=$(($SUB_DIR + 1))
        mkdir -p $SUB_DIR
    fi
    export JOB_COUNT=$(($JOB_COUNT + 1))

    # generate the job from the template    
    envsubst <search.template >$SUB_DIR/$JOB_COUNT.submit

    # add job to the dag
    cat >>sra.dag <<EOF

JOB  ID$JOB_COUNT  $JOB_COUNT.submit  DIR $SUB_DIR
RETRY ID$JOB_COUNT 3
PARENT INDEX CHILD ID$JOB_COUNT
PARENT ID$JOB_COUNT CHILD PREPARE_OUTPUTS
EOF
fi

echo "Created $JOB_COUNT jobs to process $SRA_COUNT ids"

condor_submit_dag -notification NEVER -maxidle 1000 sra.dag


